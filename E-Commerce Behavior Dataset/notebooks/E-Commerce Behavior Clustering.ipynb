{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomKMeans Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomKMeans:\n",
    "    def __init__(self, k, max_iter=300, tol=0.001):\n",
    "        self.k = k # Number of clusters\n",
    "        self.max_iter = max_iter # Maximum number of iterations for KMeans\n",
    "        self.tol = tol # Tolerance level to stop iterations\n",
    "        self.centroids = None # Used to store centroids\n",
    "        self.labels = None # Used to store the cluster assignments\n",
    "\n",
    "    #Fits the KMeans model to the data\n",
    "    def fit(self, df):\n",
    "        self.dataframe = df.to_numpy()\n",
    "        n_samples, n_features = self.dataframe.shape\n",
    "\n",
    "        # Randomly assign 'k' number of centroids from the data points\n",
    "        self.centroids = self.dataframe[np.random.choice(n_samples, self.k, replace=False)]\n",
    "\n",
    "        # Iterate for 'max_iter' number of times\n",
    "        for i in range(self.max_iter):\n",
    "            # Assigns each data point to the nearest centroid\n",
    "            self.labels = self._euclidean(self.dataframe)\n",
    "            # Calculate new centroids based on the current assignment clusters\n",
    "            new_centroids = self._calc_Centroids(self.dataframe)\n",
    "            # Check if the centroids have moved less than the tolerance value\n",
    "            if np.all(np.abs(new_centroids - self.centroids) < self.tol):\n",
    "                break\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "    # Predicts the cluster of each data point in a dataframe\n",
    "    def predict(self, df):\n",
    "        # Convert dataframe to NumPy array\n",
    "        dataframe = df.to_numpy()\n",
    "        if self.centroids is None:\n",
    "            raise ValueError(\"Model has not been fitted yet\")\n",
    "        # Assigns the new points to the closest centroid\n",
    "        return self._euclidean(dataframe)\n",
    "\n",
    "    # Method that returns the dissimilarity or Sum of Squared Errors for the clustering solution\n",
    "    def sse(self):\n",
    "        if self.labels is None or self.centroids is None:\n",
    "            raise ValueError(\"Model has not been fitted yet\")\n",
    "        sse = 0\n",
    "        # Iterate over each cluster and its centroid\n",
    "        for i, centroid in enumerate(self.centroids):\n",
    "            cluster_points = np.where(self.labels == i)[0]\n",
    "            # Compute the squared differences between points and the centroid and get their sum\n",
    "            sse += np.sum(np.square(self.dataframe[cluster_points] - centroid))\n",
    "\n",
    "        return sse\n",
    "\n",
    "    # Helper method to assign each data point to the nearest centroid based on Euclidean distance\n",
    "    def _euclidean(self, df):\n",
    "        #Calculates the Euclidean distance from each point to the centroid\n",
    "        distances = np.array([np.linalg.norm(df - centroid, axis=1) for centroid in self.centroids])\n",
    "        #Assigns each data point to the nearest centroid\n",
    "        return np.argmin(distances, axis=0)\n",
    "\n",
    "    # Helper method to calculate the new centroids as the mean of points assigned to each cluster\n",
    "    def _calc_Centroids(self, df):\n",
    "        # Initialize an array to store the new centroids\n",
    "        centroids = np.zeros((self.k, df.shape[1]))\n",
    "        # Iterate over each cluster\n",
    "        for j in range(self.k):\n",
    "            # Accumulate all the points that are assigned to the cluster\n",
    "            cluster_points = df[self.labels == j]\n",
    "            # If there are points in the cluster, calculate their mean to create the new centroid\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[j] = cluster_points.mean(axis=0)\n",
    "        return centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using CustomKMeans Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 Random Entries from Price and Product_ID\n",
    "sampled_prices = df['price'].sample(n=1000, replace=False).reset_index(drop=True)\n",
    "sampled_product_ids = df['product_id'].sample(n=1000, replace=False).reset_index(drop=True)\n",
    "\n",
    "# Create a a Sampled Dataframe\n",
    "sampled_data = pd.DataFrame({\n",
    "    'price': sampled_prices,\n",
    "    'product_id': sampled_product_ids\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Custom KMeans (c_kmeans) implementation\n",
    "\n",
    "\n",
    "def plot_clusters(sampled_data, kmeans):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(sampled_data['price'], sampled_data['product_id'], c=sampled_data['cluster'], cmap='viridis', alpha=0.6)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Product ID')\n",
    "    plt.title('K-Means Clustering of Sampled Prices and Product IDs')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,10):\n",
    "    #Use the KMeans on the sampled data frame we just made (x1 = price, x2 = product_id)\n",
    "    kmeans = CustomKMeans(k=i)\n",
    "\n",
    "    #Finds best centroids\n",
    "    kmeans.fit(sampled_data)\n",
    "\n",
    "    #Predict what data is best around said clusters\n",
    "    sampled_data['cluster'] = kmeans.predict(sampled_data)\n",
    "    \n",
    "    plot_clusters(sampled_data, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using SkLearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare it to the SkLearn version, lets use k = 5\n",
    "\n",
    "# Run custom k-means over the clusters dataset with 5 clusters\n",
    "#Use the KMeans on the sampled data frame we just made (x1 = price, x2 = product_id)\n",
    "kmeans = CustomKMeans(k=5)\n",
    "\n",
    "#Finds best centroids\n",
    "kmeans.fit(sampled_data)\n",
    "\n",
    "#Predict what data is best around said clusters\n",
    "sampled_data['cluster'] = kmeans.predict(sampled_data)\n",
    "    \n",
    "plot_clusters(sampled_data, kmeans)\n",
    "\n",
    "print(\"Now doing sklearn version\")\n",
    "# Run k-means over the clusters dataset with 5 clusters\n",
    "km = KMeans(n_clusters=5)\n",
    "clusters = km.fit(sampled_data)\n",
    "km.cluster_centers_\n",
    "#labels = (km.labels_) # Array of all labels\n",
    "plot_clusters(sampled_data, km)\n",
    "\n",
    "# Create a line plot showing the inertia (SSE) for each n_clusters value\n",
    "inertia = []\n",
    "\n",
    "\n",
    "for (i) in range(1,15):\n",
    "  km = KMeans(n_clusters=i)\n",
    "  clusters = km.fit(sampled_data)\n",
    "  inertia.append(km.inertia_)\n",
    "\n",
    "plt.plot(inertia)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
