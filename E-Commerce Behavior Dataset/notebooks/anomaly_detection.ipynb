{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/cleaned_data.csv\", parse_dates=['event_time'])\n",
    "df = df.sample(n=50000, random_state=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        event_time event_type  product_id  \\\n",
      "18380884 2019-10-22 05:20:20+00:00       view     3601485   \n",
      "16999937 2019-10-20 13:54:08+00:00       view    12100456   \n",
      "16260397 2019-10-19 17:34:11+00:00       view     1005160   \n",
      "21484014 2019-10-25 15:05:38+00:00       view     1005101   \n",
      "20900754 2019-10-25 02:34:55+00:00       view     1003312   \n",
      "\n",
      "                  category_id              category_code   brand   price  \\\n",
      "18380884  2053013563810775923  appliances.kitchen.washer      lg  308.63   \n",
      "16999937  2053013555816432043                kids.skates   kugoo  260.47   \n",
      "16260397  2053013555631882655     electronics.smartphone  xiaomi  224.68   \n",
      "21484014  2053013555631882655     electronics.smartphone  xiaomi  431.93   \n",
      "20900754  2053013555631882655     electronics.smartphone   apple  690.73   \n",
      "\n",
      "            user_id                          user_session  event_hour  \\\n",
      "18380884  534946088  b62bf744-b5e0-4c32-9f0d-e292feb295f6           5   \n",
      "16999937  562176256  f939ecff-4b8b-45af-a7ae-40826cb544ff          13   \n",
      "16260397  512560838  288f6126-b42e-4238-a815-68f4e6ad309a          17   \n",
      "21484014  519878738  78ca679b-95f0-40f4-9e47-36802ba13ed2          15   \n",
      "20900754  563884224  5a75c442-d469-416a-b7ef-5b2b288d423a           2   \n",
      "\n",
      "          event_type_encoded  \n",
      "18380884                 2.0  \n",
      "16999937                 2.0  \n",
      "16260397                 2.0  \n",
      "21484014                 2.0  \n",
      "20900754                 2.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#Initialize the encoder\n",
    "oe = OrdinalEncoder()\n",
    " \n",
    "#Get just the hour of the event occurrence\n",
    "df['event_hour'] = df['event_time'].dt.hour\n",
    "\n",
    "#Extract & Encode\n",
    "colsToEncode = ['event_type']\n",
    "encodedCols = oe.fit_transform(df[colsToEncode])\n",
    "\n",
    "#Add the encoded values to new columns\n",
    "df['event_type_encoded'] = encodedCols[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: [0 0 0 ... 0 0 0]\n",
      "LOF scores: [1. 1. 1. ... 1. 1. 1.]\n",
      "Total Number of Outliers: 24\n"
     ]
    }
   ],
   "source": [
    "#Purpose of this is to predict the price of an item given the time of day it is purchased\n",
    "#So drop the price column\n",
    "X = df.drop(columns=['price', 'user_id', 'user_session', 'category_code', 'brand','category_id', 'product_id', 'event_time', 'event_type'])\n",
    "y = df[[\"price\"]]\n",
    "\n",
    "import scipy\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "\n",
    "#LOF model with 10 neighbors\n",
    "lof = LOF(n_neighbors=10)\n",
    "\n",
    "#Fit model\n",
    "lof.fit(X)\n",
    "\n",
    "#Extract labels and scores\n",
    "labels = lof.labels_\n",
    "scores = lof.decision_scores_\n",
    "\n",
    "\n",
    "\n",
    "df['Outliers'] = labels\n",
    "\n",
    "print(\"Outliers:\", labels)\n",
    "print(\"LOF scores:\", scores)\n",
    "\n",
    "numOutliers = (df['Outliers'] == 1).sum()\n",
    "print(f\"Total Number of Outliers: {numOutliers}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try to predict anomalous prices per category, perhaps to represent luxury items.\n",
    "#Initialize the encoder\n",
    "oeTwo = OrdinalEncoder()\n",
    " \n",
    "\n",
    "#Extract and Encode\n",
    "encoded_category_code = oe.fit_transform(df[['category_code']])\n",
    "encoded_brand = oe.fit_transform(df[['brand']])\n",
    "\n",
    "#Put into new columns\n",
    "df['encoded_category_code'] = encoded_category_code\n",
    "df['encoded_brand'] = encoded_brand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: [0 0 0 ... 0 0 0]\n",
      "LOF scores: [1. 1. 1. ... 1. 1. 1.]\n",
      "Total Number of Outliers: 24\n"
     ]
    }
   ],
   "source": [
    "#Same as before\n",
    "X = df[['encoded_category_code', 'encoded_brand']]\n",
    "y = df[[\"price\"]] \n",
    "\n",
    "lof = LOF(n_neighbors=10)\n",
    "lof.fit(X)\n",
    "\n",
    "\n",
    "df['Outliers'] = labels\n",
    "\n",
    "print(\"Outliers:\", labels)\n",
    "print(\"LOF scores:\", scores)\n",
    "\n",
    "#Get outliers\n",
    "numOutliers = (df['Outliers'] == 1).sum()\n",
    "print(f\"Total Number of Outliers: {numOutliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: [0 0 0 ... 1 0 0]\n",
      "LOF scores: [0.98873923 1.00135211 1.01834153 ... 1.07506541 1.04051256 1.01393246]\n",
      "Total Number of Outliers: 5000\n"
     ]
    }
   ],
   "source": [
    "#User behavior anomalies\n",
    "\n",
    "oeThree = OrdinalEncoder()\n",
    "\n",
    "encoded_user_id = oe.fit_transform(df[['user_id']])\n",
    "encoded_user_session = oe.fit_transform(df[['user_session']])\n",
    "df['encoded_user_id'] = encoded_user_id\n",
    "df['encoded_user_session'] = encoded_user_session\n",
    "\n",
    "\n",
    "X = df[['encoded_user_id', 'encoded_user_session']]\n",
    "\n",
    "lof = LOF(n_neighbors = 10)\n",
    "lof.fit(X)\n",
    "\n",
    "\n",
    "labels = lof.labels_\n",
    "scores = lof.decision_scores_\n",
    "\n",
    "df['Outliers'] = labels\n",
    "\n",
    "print(\"Outliers:\", labels)#\n",
    "print(\"LOF scores:\", scores)\n",
    "\n",
    "#Get outliers\n",
    "numOutliers = (df['Outliers'] == 1).sum()\n",
    "print(f\"Total Number of Outliers: {numOutliers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Outlier Factor (LOF) is the algorithm that was implemented on the dataset. Local Outlier Factor has 7 steps that should be focused on. These steps include calculating the distance between points, determining k and k-nearest neighbors, computing reachability distances, calculating the Local Reachability Density for each point, computing the LOF score for each point, and identifying outliers based on the score. \n",
    "\n",
    "\t1.Calculate Distances\n",
    "\t    a. Measure the distance between each pair of points in the dataset\n",
    "\t    b. If you have an n-dimensional dataset, calculate the Euclidean distance between every pair of points \n",
    "\t\n",
    "    2.Determine k\n",
    "\t    a. Decide on a number k that will indicate the number of neighbors to consider for each point. \n",
    "\t    b. Larger k-values work better with larger datasets and vice versa. \n",
    "\t\n",
    "    3.Find k-distance for each point\n",
    "\t    a. Sort the distances to all other points\n",
    "\t    b. Identify the distance to the kth nearest neighbor\n",
    "\t    c. The points within that distance are k-nearest neighbors \n",
    "\t\n",
    "    4.Computing Reachability Distance\n",
    "\t    a. Use this formula to compute the reachability distance \n",
    "\t        i. P = point, N = k-nearest neighbor\n",
    "\t        ii. reachability distance(P,N) = max(k distance(N),distance(P,N))\n",
    "\t\n",
    "    5.Calculate the Local Reachability Density\n",
    "\t    a. Use this formula to compute the Local Reachability Density\n",
    "\t        i. For each point P\n",
    "\t            1. Sum the reachability distances from P to each of its k-nearest neighbors\n",
    "\t            2. Divide k by this sum to get the Local Reachability Density\n",
    "\t            3. LRD(P) = k /∑N in k nearest neighbors of Preachability distance(P,N)k \n",
    "\t\n",
    "    6.Calculate the LOF Score\n",
    "\t    a. Find all the Local Reachability Densities of all P’s k-nearest neighbors\n",
    "\t    b. Use this formula to calculate the Local Outlier Factor for P \n",
    "\t        i. Average the ratio of the LRDs of P’s neighbors to the Local Reachability Density of P \n",
    "\t        ii. LOF(P) = 1/k N in k nearest neighbors of P∑ LRD(N)/LRD(P) \n",
    "\t\n",
    "    7.Identify Anomalies\n",
    "\t    a. Review the LOF scores\n",
    "\t    b. Set a threshold for outlet detection (for example, points with an LOF score of 1.5-2 or above can be considered outliers) \n",
    "\t    c. Points with LOF scores that are above the set threshold can be outliers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were definitely anomalies, only 24 each for the price-based ones, but 5000 for the user activity based ones.\n",
    "\n",
    "I think for the first set of anomalies, the anomalies that were based on the price given brand attributes and the price of an item an action was done to at a time of day, it makes sense that they would be so low. For the price given brand attributes, it makes sense most brands would keep a consistent pricing structure. I thought some items may be varied in price, but it seems that variance is accounted for. As for the price relating to actions at a time of day, this one makes sense to have so few anomalies as well. The time of day you purchase an item wouldn't have much correlation with the price of the item you're chosing to buy.\n",
    "\n",
    "It was interesting to see 5,000 anomalies (from a sample of 50,000) for determining oddities in user behavior. A few explanations is that for some users, a low amount of entries may account for skew. So if they only view, then finally bought (as if scouting out product), then it makes sense. New users would be especially susceptible to this. Only one deviant action would account for an outlier. Another possibility is that some users use their accounts far more often, where as some don't. It is possible some accounts also spend far more than others, due to larger households or perhaps for business purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
